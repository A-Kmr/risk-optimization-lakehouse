{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a926f91-aa7a-46f7-9b27-58dd1dc59ab6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 02_Silver_Cleaning (v2 - Safe Mode)\n",
    "# Goal: Clean raw data and create the 'default_flag' target\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from pyspark.sql.functions import col, when, regexp_replace\n",
    "\n",
    "# 1. Load Bronze Data\n",
    "print(\"â³ Loading Bronze Table...\")\n",
    "df = spark.table(\"bronze_lending_club\")\n",
    "\n",
    "# 2. Filter: Keep only Completed Loans\n",
    "print(\"ðŸ§¹ Filtering for 'Fully Paid' or 'Charged Off'...\")\n",
    "df_silver = df.filter(col(\"loan_status\").isin(\"Fully Paid\", \"Charged Off\"))\n",
    "\n",
    "# 3. Create Target Variable (1 = Default, 0 = Paid)\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"default_flag\", \n",
    "    when(col(\"loan_status\") == \"Charged Off\", 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# 4. Clean Feature: 'term' (Remove \" months\" and convert to Int)\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"term_clean\", \n",
    "    regexp_replace(col(\"term\"), \" months\", \"\").cast(\"int\")\n",
    ")\n",
    "\n",
    "# 5. Clean Feature: 'emp_length' (Extract numbers, e.g. \"10+ years\" -> 10)\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"emp_length_clean\", \n",
    "    when(\n",
    "        regexp_replace(col(\"emp_length\"), \"[^0-9]\", \"\") == \"\", \n",
    "        None\n",
    "    ).otherwise(\n",
    "        regexp_replace(col(\"emp_length\"), \"[^0-9]\", \"\").cast(\"int\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 6. Select Columns (REMOVED 'fico_range_low' to fix error)\n",
    "cols_to_keep = [\n",
    "    \"loan_amnt\",            # Amount requested\n",
    "    \"int_rate\",             # Interest Rate\n",
    "    \"installment\",          # Monthly payment\n",
    "    \"annual_inc\",           # Income\n",
    "    \"dti\",                  # Debt-to-Income Ratio\n",
    "    \"term_clean\",           # Loan duration\n",
    "    \"emp_length_clean\",     # Stability\n",
    "    \"home_ownership\",       # Collateral\n",
    "    \"purpose\",              # Reason for loan\n",
    "    \"addr_state\",           # Geography\n",
    "    \"default_flag\"          # Target\n",
    "]\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_final = df_silver.select(cols_to_keep).dropna()\n",
    "\n",
    "# 7. Save to Silver Delta Table\n",
    "table_name = \"silver_lending_club\"\n",
    "print(f\"ðŸ’¾ Saving to Silver Table: {table_name}...\")\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "# --- VALIDATION ---\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸš€ SUCCESS! Silver Table Created.\")\n",
    "print(f\"ðŸ“Š Rows after cleaning: {spark.table(table_name).count():,}\")\n",
    "print(f\"ðŸ’€ Default Rate: {df_final.filter('default_flag = 1').count() / df_final.count():.2%}\")\n",
    "print(\"-\" * 30)\n",
    "display(spark.table(table_name).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Silver_Cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
