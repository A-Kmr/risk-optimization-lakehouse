{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd487f0-b6e8-4d98-bcdb-cfbf4fa5f4fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 01_Bronze_Ingestion\n",
    "# Goal: Ingest raw Lending Club data into the Bronze Delta Layer\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Path to the uploaded zip file in your Unity Catalog Volume\n",
    "zip_file_path = \"/Volumes/workspace/default/raw_data/archive.zip\"\n",
    "# Directory where we will extract the CSV\n",
    "extract_path = \"/Volumes/workspace/default/raw_data/\"\n",
    "\n",
    "print(f\"üìÇ Source File: {zip_file_path}\")\n",
    "\n",
    "# --- STEP 1: UNZIP THE DATA ---\n",
    "# We use a shell command to unzip the file directly in the volume\n",
    "print(\"‚è≥ Unzipping file... (This may take 1-2 minutes)...\")\n",
    "try:\n",
    "    # -n means 'never overwrite' (faster if already unzipped), -d is destination\n",
    "    subprocess.check_call(f\"unzip -n {zip_file_path} -d {extract_path}\", shell=True)\n",
    "    print(\"‚úÖ Unzip Successful!\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"‚ö†Ô∏è  Warning: Unzip might have failed or file already exists.\")\n",
    "\n",
    "# --- STEP 2: IDENTIFY THE CSV ---\n",
    "# The zip usually contains 'accepted_2007_to_2018Q4.csv' or similar\n",
    "files = [f for f in os.listdir(extract_path) if f.endswith(\".csv\")]\n",
    "if not files:\n",
    "    raise Exception(f\"‚ùå No CSV found in {extract_path}. Check the upload.\")\n",
    "\n",
    "csv_name = files[0]\n",
    "full_csv_path = os.path.join(extract_path, csv_name)\n",
    "print(f\"üìÑ Found CSV: {full_csv_path}\")\n",
    "\n",
    "# --- STEP 3: WRITE TO DELTA (BRONZE LAYER) ---\n",
    "# Read CSV with Spark (Optimized for large files)\n",
    "print(\"üíæ Reading CSV into Spark DataFrame...\")\n",
    "df_raw = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option(\"header\", \"true\")\n",
    "          .option(\"inferSchema\", \"true\") # Automatically detect Int/Float/String\n",
    "          .load(full_csv_path))\n",
    "\n",
    "# Save as a Delta Table (The Industry Standard)\n",
    "# This creates a permanent table in your Metastore\n",
    "table_name = \"bronze_lending_club\"\n",
    "print(f\"üî® Creating Delta Table: {table_name}...\")\n",
    "\n",
    "df_raw.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "# --- VALIDATION ---\n",
    "print(\"-\" * 30)\n",
    "print(f\"üöÄ SUCCESS! Table '{table_name}' created.\")\n",
    "print(f\"üìä Total Rows: {spark.table(table_name).count():,}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Display the first 5 rows to verify\n",
    "display(spark.table(table_name).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
